{
 "metadata": {
  "name": "",
  "signature": "sha256:6276b0e99c855ebcef8620635eec360e8900af8d897f7f176ab2c0339e292022"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Task solution: Sequencing"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "GenBank hosts E Coli genomes [here](http://www.ncbi.nlm.nih.gov/genome/167). I choose [this release](http://www.ncbi.nlm.nih.gov/nuccore/556503834) for no reason, except that it seems to contain good gene annotation.\n",
      "\n",
      "We could easily download it from there, but as we want to have an exercise, let us do it programatically with the the help of BioPython. We could also not use BioPython at all and reprogram everything in pure Python, for an even greater challange, but as long as the code is simple enough, the fastest way is the best way."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from Bio import Entrez\n",
      "Entrez.email = \"sn@mail.at\"\n",
      "handle = Entrez.esearch(db='nuccore', term='escherichia coli[orgn] AND complete genome[title]')\n",
      "genome_ids = Entrez.read(handle)['IdList']\n",
      "print genome_ids"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['817696214', '817695621', '817589947', '817585806', '817581666', '817577526', '817573384', '817146391', '469801541', '452723576', '418300889', '816208797', '544574430', '814569385', '814569384', '814569383', '814566399', '814566398', '814566395', '814565977']\n"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So we have several releases and we will pick now one arbitrarily. We can do that since this is merely a learning study. The variable handle is inheriting from a file object. You can see that from the object introspection that it has methods to read the lines, but not for writing."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from Bio import Entrez\n",
      "Entrez.email = \"your@mail.com\" #put real mail\n",
      "\n",
      "handle = Entrez.efetch(db=\"nuccore\", id=['556503834'], rettype=\"gbwithparts\", retmode=\"txt\")\n",
      "#print \"First 2000 characters:\"\n",
      "#print(handle.read()[:2000])#first 2000 characters\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As a parantheses, to get the full fasta file is extremely simple:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "handle2 = Entrez.efetch(db=\"nucleotide\", id=['556503834'], rettype=\"fasta\", retmode=\"txt\")\n",
      "print(handle2.read()[:500])\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ">gi|556503834|ref|NC_000913.3| Escherichia coli str. K-12 substr. MG1655, complete genome\n",
        "AGCTTTTCATTCTGACTGCAACGGGCAATATGTCTCTGTGTGGATTAAAAAAAGAGTGTCTGATAGCAGC\n",
        "TTCTGAACTGGTTACCTGCCGTGAGTAAATTAAAATTTTATTGACTTAGGTCACTAAATACTTTAACCAA\n",
        "TATAGGCATAGCGCACAGACAGATAAAAATTACAGAGTACACAACATCCATGAAACGCATTAGCACCACC\n",
        "ATTACCACCACCATCACCATTACCACAGGTAACGGTGCGGGCTGACGCGTACAGGAAACACAGAAAAAAG\n",
        "CCCGCACCTGACAGTGCGGGCTTTTTTTTTCGACCAAAGGTAACGAGGTAACAACCATGCGAGTGTTGAA\n",
        "GTTCGGCGGTACATCAGTGGCAAATGCAGAACGTTTTCTGCGTGTTGCCGATATT\n"
       ]
      }
     ],
     "prompt_number": 42
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Right now the data is in the \"handle\" variable. We need a new file descriptor to save the data on our computer. For a quick documentation check:\n",
      "\n",
      "[http://biopython.org/DIST/docs/tutorial/Tutorial.html#htoc114](http://biopython.org/DIST/docs/tutorial/Tutorial.html#htoc114)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fout = open(\"data/ecoli.gbk\", \"w\")\n",
      "fout.write(handle.read())\n",
      "fout.close()\n",
      "#handle.close()\n",
      "print(\"Saved\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Saved\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I extracted intergenic regions using the script referenced in the task description:\n",
      "[http://bytesizebio.net/2010/02/11/short-bioinformatic-hacks-reading-between-the-genes/](http://bytesizebio.net/2010/02/11/short-bioinformatic-hacks-reading-between-the-genes/)\n",
      "\n",
      "Note that some features have failed to be parsed. They all seem to be spanning multiple locations. We will not bother with them."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import Bio\n",
      "from Bio import SeqIO, SeqFeature\n",
      "from Bio.SeqRecord import SeqRecord\n",
      "import os\n",
      "\n",
      "# Copyright(C) 2009 Iddo Friedberg & Ian MC Fleming\n",
      "# Released under Biopython license. http://www.biopython.org/DIST/LICENSE\n",
      "# Do not remove this comment\n",
      "def get_interregions(genbank_path,intergene_length=1):\n",
      "    seq_record = SeqIO.parse(open(genbank_path), \"genbank\").next()\n",
      "    cds_list_plus = []\n",
      "    cds_list_minus = []\n",
      "    intergenic_records = []\n",
      "    # Loop over the genome file, get the CDS features on each of the strands\n",
      "    for feature in seq_record.features:\n",
      "        if feature.type == 'CDS':\n",
      "            try:\n",
      "                mystart = feature.location._start.position\n",
      "                myend = feature.location._end.position\n",
      "                if feature.strand == -1:\n",
      "                    cds_list_minus.append((mystart,myend,-1))\n",
      "                elif feature.strand == 1:\n",
      "                    cds_list_plus.append((mystart,myend,1))\n",
      "                else:\n",
      "                    sys.stderr.write(\"No strand indicated %d-%d. Assuming +\\n\" %\n",
      "                                      (mystart, myend))\n",
      "                    cds_list_plus.append((mystart,myend,1))\n",
      "            except Exception:\n",
      "                pass\n",
      "                #print \"Exception at:\"\n",
      "                #print feature\n",
      "                \n",
      "\n",
      "    for i,pospair in enumerate(cds_list_plus[1:]):\n",
      "        # Compare current start position to previous end position\n",
      "        last_end = cds_list_plus[i][1]\n",
      "        this_start = pospair[0]\n",
      "        strand = pospair[2]\n",
      "        if this_start - last_end >= intergene_length:\n",
      "            intergene_seq = seq_record.seq[last_end:this_start]\n",
      "            strand_string = \"+\"\n",
      "            intergenic_records.append(\n",
      "                  SeqRecord(intergene_seq,id=\"%s-ign-%d\" % (seq_record.name,i),\n",
      "                  description=\"%s %d-%d %s\" % (seq_record.name, last_end+1,\n",
      "                                                        this_start,strand_string)))\n",
      "    for i,pospair in enumerate(cds_list_minus[1:]):\n",
      "        last_end = cds_list_minus[i][1]\n",
      "        this_start = pospair[0]\n",
      "        strand = pospair[2]\n",
      "        if this_start - last_end >= intergene_length:\n",
      "            intergene_seq = seq_record.seq[last_end:this_start]\n",
      "            strand_string = \"-\"\n",
      "            intergenic_records.append(\n",
      "                  SeqRecord(intergene_seq,id=\"%s-ign-%d\" % (seq_record.name,i),\n",
      "                  description=\"%s %d-%d %s\" % (seq_record.name, last_end+1,\n",
      "                                                        this_start,strand_string)))\n",
      "    outpath = \"data/ecoli_ign.fasta\"\n",
      "    SeqIO.write(intergenic_records, open(outpath,\"w\"), \"fasta\")\n",
      "    print \"Done!\"\n",
      "\n",
      "get_interregions(\"data/ecoli.gbk\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Done!\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To further accomplish our task we could modify the script above to extract let's say 400 nucleotides upstream from every gene. If you did not pay attention now is the time to try to understand the code, since it is simplified and more educational."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import Bio\n",
      "from Bio import SeqIO, SeqFeature, SeqRecord\n",
      "import os\n",
      "\n",
      "gbf = \"data/ecoli.gbk\"\n",
      "promoters = []\n",
      "\n",
      "record = SeqIO.parse(open(gbf), \"genbank\").next()\n",
      "dnaseq = record.seq # seq is an attribute of the record object containing the actual nucleotide sequence as a string\n",
      "\n",
      "## We fill the CDS list first\n",
      "cds = []#CDS features list\n",
      "for feature in record.features:\n",
      "    if feature.type == 'CDS':\n",
      "        #print dir(feature)\n",
      "        #print feature\n",
      "        #print feature.qualifiers\n",
      "        #break\n",
      "        try:\n",
      "            mystart = feature.location._start.position\n",
      "            myend = feature.location._end.position\n",
      "            ## we annotate the promoters with the NumProt id of coresponding to the referenced gene\n",
      "            ## how did I knew this, by simple object interogation - uncomment the lines above to understand it\n",
      "            pid = feature.qualifiers['protein_id'][0]\n",
      "            if feature.strand == 1:\n",
      "                cds.append((mystart,myend,pid))\n",
      "        except Exception:\n",
      "            pass # being careless about the CDSes spanning multiple locations!\n",
      "\n",
      "## Extract the promoter regions in a list of SeqRecord objects\n",
      "for i,pospair in enumerate(cds):\n",
      "    start, end, pid = pospair\n",
      "    pseq = dnaseq[start-400:start] # dnaseq is a string, so we can slice it directly\n",
      "    promid = 'p_'+ pid\n",
      "    pdesc = \"%s, 400 bp upstream promoter, %d-%d\" % (record.name, start-400, start)\n",
      "    ## Note that BioPython named a class with the same name as its module, this is frequent in OOP and somewhat funny \n",
      "    prec = SeqRecord.SeqRecord(pseq, id=promid, description = pdesc)\n",
      "    promoters.append(prec)\n",
      "\n",
      "## Write all promoters on file\n",
      "outpath = \"data/ecoli_prom.fasta\"\n",
      "SeqIO.write(promoters, open(outpath,\"w\"), \"fasta\")\n",
      "print \"Done!\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Done!\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(cds)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 74,
       "text": [
        "0"
       ]
      }
     ],
     "prompt_number": 74
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from Bio import Entrez\n",
      "Entrez.__file__"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "'/usr/lib/python2.7/dist-packages/Bio/Entrez/__init__.pyc'"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we finally have the promoters, so after I get a cofee we start \"blasting\" them into each other. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from subprocess import Popen, PIPE\n",
      "\n",
      "class Command( object ):\n",
      "    def __init__( self, args ):\n",
      "        self.args = args\n",
      "    def execute( self ):\n",
      "        #print self.args\n",
      "        p = Popen(self.args, shell = False, stdin=None, stdout=PIPE, stderr=None)\n",
      "        result = p.communicate()[0]\n",
      "        print result\n",
      "        status = p.wait()\n",
      "        self.stdin, self.stdout, self.stderr = p.stdin, p.stdout, p.stderr\n",
      "        \n",
      "t1 = \"makeblastdb -in data/ecoli_prom.fasta -dbtype nucl -out data/prom.db\"\n",
      "t2 = \"blastn -db data/prom.db -query data/ecoli_prom.fasta -out data/ecoli_promblast.txt -outfmt 6\"\"\n",
      "t1args = t1.split()\n",
      "t2args = t2.split()\n",
      "\n",
      "pipeline = [Command(t1args), Command(t2args)]\n",
      "\n",
      "for c in pipeline:\n",
      "    print \"Running command:\", \" \".join(c.args)\n",
      "    c.execute()\n",
      "    print \"Input:\", c.stdin\n",
      "    print \"Output:\", c.stdout\n",
      "    print \"Error:\", c.stderr\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Running command: makeblastdb -in data/ecoli_prom.fasta -dbtype nucl -out data/prom.db\n",
        "\n",
        "\n",
        "Building a new DB, current time: 05/13/2015 15:02:53\n",
        "New DB name:   data/prom.db\n",
        "New DB title:  data/ecoli_prom.fasta\n",
        "Sequence type: Nucleotide\n",
        "Keep Linkouts: T\n",
        "Keep MBits: T\n",
        "Maximum file size: 1000000000B\n",
        "Ignoring sequence 'lcl|1' as it has no sequence data\n",
        "Ignoring sequence 'lcl|2' as it has no sequence data\n",
        "Adding sequences from FASTA; added 2010 sequences in 0.0863168 seconds.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Input: None\n",
        "Output: <closed file '<fdopen>', mode 'rb' at 0x7f37fc0aee40>\n",
        "Error: None\n",
        "Running command: blastn -db data/prom.db -query data/ecoli_prom.fasta -out data/ecoli_promblast.txt -outfmt 6\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Input: None\n",
        "Output: <closed file '<fdopen>', mode 'rb' at 0x7f37e63c8c90>\n",
        "Error: None\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let us not open the output from Blast in a pandas dataframe and sort it by te e-value column. Although a poor indicator of local similarity  it taken alone, for our purpose will suffice. I leave a more appropriate level of selection to you. The last step we will be using the remote NCBI Blast to search for similar proteins.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "\n",
      "df = pd.read_csv(\"data/ecoli_promblast.txt\", header = None, sep = \"\\t\")\n",
      "df[df[10]>0].sort(10).iloc[:10,:]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>0</th>\n",
        "      <th>1</th>\n",
        "      <th>2</th>\n",
        "      <th>3</th>\n",
        "      <th>4</th>\n",
        "      <th>5</th>\n",
        "      <th>6</th>\n",
        "      <th>7</th>\n",
        "      <th>8</th>\n",
        "      <th>9</th>\n",
        "      <th>10</th>\n",
        "      <th>11</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>450 </th>\n",
        "      <td>    p_NP_415092.1</td>\n",
        "      <td>    p_YP_588454.1</td>\n",
        "      <td>  95.83</td>\n",
        "      <td> 384</td>\n",
        "      <td> 16</td>\n",
        "      <td> 0</td>\n",
        "      <td>  13</td>\n",
        "      <td> 396</td>\n",
        "      <td> 400</td>\n",
        "      <td>  17</td>\n",
        "      <td> 2.000000e-179</td>\n",
        "      <td> 621</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1112</th>\n",
        "      <td>    p_YP_588454.1</td>\n",
        "      <td>    p_NP_415092.1</td>\n",
        "      <td>  95.83</td>\n",
        "      <td> 384</td>\n",
        "      <td> 16</td>\n",
        "      <td> 0</td>\n",
        "      <td>  17</td>\n",
        "      <td> 400</td>\n",
        "      <td> 396</td>\n",
        "      <td>  13</td>\n",
        "      <td> 2.000000e-179</td>\n",
        "      <td> 621</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>423 </th>\n",
        "      <td> p_YP_001165308.1</td>\n",
        "      <td>    p_NP_415079.1</td>\n",
        "      <td> 100.00</td>\n",
        "      <td> 302</td>\n",
        "      <td>  0</td>\n",
        "      <td> 0</td>\n",
        "      <td>  99</td>\n",
        "      <td> 400</td>\n",
        "      <td>   1</td>\n",
        "      <td> 302</td>\n",
        "      <td> 2.000000e-160</td>\n",
        "      <td> 558</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>425 </th>\n",
        "      <td>    p_NP_415079.1</td>\n",
        "      <td> p_YP_001165308.1</td>\n",
        "      <td> 100.00</td>\n",
        "      <td> 302</td>\n",
        "      <td>  0</td>\n",
        "      <td> 0</td>\n",
        "      <td>   1</td>\n",
        "      <td> 302</td>\n",
        "      <td>  99</td>\n",
        "      <td> 400</td>\n",
        "      <td> 2.000000e-160</td>\n",
        "      <td> 558</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1261</th>\n",
        "      <td> p_YP_002791242.1</td>\n",
        "      <td> p_YP_002791243.1</td>\n",
        "      <td> 100.00</td>\n",
        "      <td> 299</td>\n",
        "      <td>  0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 102</td>\n",
        "      <td> 400</td>\n",
        "      <td>   1</td>\n",
        "      <td> 299</td>\n",
        "      <td> 8.000000e-159</td>\n",
        "      <td> 553</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1263</th>\n",
        "      <td> p_YP_002791243.1</td>\n",
        "      <td> p_YP_002791242.1</td>\n",
        "      <td> 100.00</td>\n",
        "      <td> 299</td>\n",
        "      <td>  0</td>\n",
        "      <td> 0</td>\n",
        "      <td>   1</td>\n",
        "      <td> 299</td>\n",
        "      <td> 102</td>\n",
        "      <td> 400</td>\n",
        "      <td> 8.000000e-159</td>\n",
        "      <td> 553</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>582 </th>\n",
        "      <td>    p_NP_415263.1</td>\n",
        "      <td>    p_YP_588444.1</td>\n",
        "      <td> 100.00</td>\n",
        "      <td> 287</td>\n",
        "      <td>  0</td>\n",
        "      <td> 0</td>\n",
        "      <td>   1</td>\n",
        "      <td> 287</td>\n",
        "      <td> 114</td>\n",
        "      <td> 400</td>\n",
        "      <td> 4.000000e-152</td>\n",
        "      <td> 531</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>580 </th>\n",
        "      <td>    p_YP_588444.1</td>\n",
        "      <td>    p_NP_415263.1</td>\n",
        "      <td> 100.00</td>\n",
        "      <td> 287</td>\n",
        "      <td>  0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 114</td>\n",
        "      <td> 400</td>\n",
        "      <td>   1</td>\n",
        "      <td> 287</td>\n",
        "      <td> 4.000000e-152</td>\n",
        "      <td> 531</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1027</th>\n",
        "      <td>    p_NP_415922.1</td>\n",
        "      <td>    p_NP_418693.1</td>\n",
        "      <td> 100.00</td>\n",
        "      <td> 269</td>\n",
        "      <td>  0</td>\n",
        "      <td> 0</td>\n",
        "      <td>   1</td>\n",
        "      <td> 269</td>\n",
        "      <td> 269</td>\n",
        "      <td>   1</td>\n",
        "      <td> 4.000000e-142</td>\n",
        "      <td> 497</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>294 </th>\n",
        "      <td>    p_NP_414895.1</td>\n",
        "      <td>    p_NP_415922.1</td>\n",
        "      <td> 100.00</td>\n",
        "      <td> 269</td>\n",
        "      <td>  0</td>\n",
        "      <td> 0</td>\n",
        "      <td>   1</td>\n",
        "      <td> 269</td>\n",
        "      <td> 269</td>\n",
        "      <td>   1</td>\n",
        "      <td> 4.000000e-142</td>\n",
        "      <td> 497</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 38,
       "text": [
        "                    0                 1       2    3   4   5    6    7    8   \\\n",
        "450      p_NP_415092.1     p_YP_588454.1   95.83  384  16   0   13  396  400   \n",
        "1112     p_YP_588454.1     p_NP_415092.1   95.83  384  16   0   17  400  396   \n",
        "423   p_YP_001165308.1     p_NP_415079.1  100.00  302   0   0   99  400    1   \n",
        "425      p_NP_415079.1  p_YP_001165308.1  100.00  302   0   0    1  302   99   \n",
        "1261  p_YP_002791242.1  p_YP_002791243.1  100.00  299   0   0  102  400    1   \n",
        "1263  p_YP_002791243.1  p_YP_002791242.1  100.00  299   0   0    1  299  102   \n",
        "582      p_NP_415263.1     p_YP_588444.1  100.00  287   0   0    1  287  114   \n",
        "580      p_YP_588444.1     p_NP_415263.1  100.00  287   0   0  114  400    1   \n",
        "1027     p_NP_415922.1     p_NP_418693.1  100.00  269   0   0    1  269  269   \n",
        "294      p_NP_414895.1     p_NP_415922.1  100.00  269   0   0    1  269  269   \n",
        "\n",
        "       9              10   11  \n",
        "450    17  2.000000e-179  621  \n",
        "1112   13  2.000000e-179  621  \n",
        "423   302  2.000000e-160  558  \n",
        "425   400  2.000000e-160  558  \n",
        "1261  299  8.000000e-159  553  \n",
        "1263  400  8.000000e-159  553  \n",
        "582   400  4.000000e-152  531  \n",
        "580   287  4.000000e-152  531  \n",
        "1027    1  4.000000e-142  497  \n",
        "294     1  4.000000e-142  497  "
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def blastit(handle):\n",
      "    \"\"\"We put this into a function to call it repeatedly.\n",
      "    We use the negative bit-score value to sort the results, and we only output the first hit.\n",
      "    \"\"\"\n",
      "    from Bio.Blast import NCBIXML\n",
      "    for record in NCBIXML.parse(handle):\n",
      "        if record.alignments:\n",
      "            record.alignments.sort(key = lambda align: max(hsp.score for hsp in align.hsps), reverse=True)\n",
      "            print record.alignments[0].hit_id\n",
      "    return\n",
      "\n",
      "from Bio.Blast import NCBIWWW\n",
      "result_handle = NCBIWWW.qblast(\"blastp\", \"nr\", \"NP_415092.1\")\n",
      "blastit(result_handle)\n",
      "result_handle = NCBIWWW.qblast(\"blastp\", \"nr\", \"YP_588454.1\")\n",
      "blastit(result_handle)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "gi|446375711|ref|WP_000453566.1|\n",
        "gi|485741442|ref|WP_001368374.1|"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Tell me if you have better ideas or if you spot errors. I put some helpful links here:\n",
      "\n",
      "[http://biopython.org/DIST/docs/api/Bio.Blast.NCBIWWW-module.html](http://biopython.org/DIST/docs/api/Bio.Blast.NCBIWWW-module.html)\n",
      "\n",
      "[http://www.ncbi.nlm.nih.gov/BLAST/blastcgihelp.shtml](http://www.ncbi.nlm.nih.gov/BLAST/blastcgihelp.shtml)\n",
      "\n",
      "[http://www.ncbi.nlm.nih.gov/books/NBK279680/](http://www.ncbi.nlm.nih.gov/books/NBK279680/)\n",
      "\n",
      "[https://docs.python.org/2/library/subprocess.html](https://docs.python.org/2/library/subprocess.html)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}